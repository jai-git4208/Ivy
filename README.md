# ğŸŒ¸ Ivy â€” Local AI Agent with System Control

Ivy is a **personal AI agent** that runs **completely offline** on your machine.
She uses [Ollama](https://ollama.ai) to run LLMs locally, a Python backend for actions (like opening apps, typing, taking screenshots), and an **Electron orb UI** for interaction.

---

## âœ¨ Features

* ğŸ’» **Runs locally** â€” no cloud, no data leaks.
* ğŸ§  **Powered by Ollama** (supports `gemma:4b`, `llama3`, etc.).
* ğŸ¤ **Speech recognition** (optional) â€” Ivy can listen to your voice.
* ğŸ”Š **Text-to-Speech (TTS)** â€” Ivy speaks back naturally.
* ğŸ–¥ï¸ **System control** (via Python):

  * `open_app` â†’ launch desktop apps (Chrome, VS Code, File Manager, etc.)
  * `keyboard_action` â†’ type text, send hotkeys, press enter
  * `click_action` â†’ click on-screen positions
  * `scroll_action` â†’ scroll up/down
  * `take_screenshot` â†’ capture and save a screenshot
* ğŸŒŒ **Beautiful UI** â€” animated gradient orb powered by Electron.js.
* âš¡ **Spacebar trigger** â€” press space to launch Ivy instantly.

---

## ğŸš€ Getting Started

### 1. Install dependencies

Make sure you have:

* **Python 3.10+** with `venv`
* **Node.js + npm**
* **Ollama** installed and running
* System utilities: `xdotool`, `gnome` apps (for app launching)
* Python packages:

  ```bash
  pip install -r requirements.txt
  ```

### 2. Clone the repo

```bash
git clone https://github.com/your-username/Ivy.git
cd Ivy
```

### 3. Setup virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 4. Create Ivy model with Ollama

From the project root:

```bash
ollama create Ivy -f Modelfile
```

### 5. Run backend (Python)

```bash
python app.py
```

### 6. Run frontend (Electron UI)

```bash
cd frontend
npm install
npm start
```

---

## ğŸ® Usage

* Start **Electron orb UI** (`npm start`).
* Press **Spacebar** â†’ orb animates + Ivy starts listening.
* Say or type a command â†’ Ivy parses it with her LLM â†’ executes Python action â†’ speaks back.

### Example commands:

* `open chrome` â†’ launches Google Chrome
* `type Hello World` â†’ types into focused window
* `take screenshot` â†’ saves a screenshot in `/home/jaimin-pansal/Ivy/screenshot.png`
* `press ctrl+c` â†’ sends hotkey

---

## ğŸ› ï¸ Tech Stack

* **AI backend** â†’ [Ollama](https://ollama.ai)
* **LLM** â†’ `gemma:4b` (custom Ivy build)
* **System actions** â†’ Python (`subprocess`, `pyautogui`, `xdotool`)
* **TTS** â†’ Murf API (with local pyttsx3 fallback)
* **Speech Recognition** â†’ `speech_recognition`
* **UI** â†’ Electron.js + Vanilla JS (Gradient Orb Animation)

---

## ğŸ”® Roadmap

* [ ] Smarter **context memory**
* [ ] Offline neural TTS for natural voice
* [ ] Offline web search integration
* [ ] More desktop automations (file manager, notifications, etc.)
* [ ] Packaged cross-platform installer

---

## ğŸ¤ Contributing

PRs and ideas are welcome! Fork this repo, hack Ivy, and share improvements.

---

## ğŸ“œ License

Apache 2.0 License Â© 2025 Jaimin Pansal

---

Made with â¤ï¸ by **Jaimin**

